\section{Constraints and Limitations}

\begin{itemize}

\item Verification is being done on the basis of precursor data sets such as HSC, and eventually with engineering data from the LSST arrays. These are just a proxy for full-focal-plane on-site LSST data.

\item Metric measurements and operational rehearsals during construction may not involve critical operational systems that are still in development. For example, while computational performance is being measured, computationally dominant algorithmic steps such as deblending and multi-fit are only modeled, since they have not yet been implemented; operational rehearsals are done without the factory LSST workflow system; etc.

\end{itemize}

\subsection{Requirements Traceability Constraints}

\begin{note}
  I felt a summary of the current state of play being verified could be useful to Wil. We don't have to leave it in the final document --FE
\end{note}

\subsubsection{Scientific}

Some science requirements are captured in \citeds{LSE-29} (aka \LSR) and  flow down to \citeds{LSE-30} (aka \OSS) ; some also exist in \citeds{LSE-163} (aka \DPDD) and will flow down in \citeds{LSE-61} (aka \DMSR).

\begin{note}
Flowdown is not complete, TJ is working on this.
\end{note}

\subsubsection{Computational}

There are requirements in \citeds{LSE-61} (aka \DMSR) which captures the \citeds{LSE-30} (\OSS) requirements that DM is responsible for. \textit{In practice \citeds{LSE-63} (the QA document) has not been flown down to \citeds{LSE-61}}. These are:

\begin{itemize}

\item The primary computational performance flown down from \citeds{LSE-29} (\LSR) is OTT1 which is the requirement to issue an alert within 60 seconds of exposure end.\dmreq{0004}\lsrreq{0101}

\item Another requirement flows down from \citeds{LSE-29} is calculation of orbits within 24 hours of the end of the observing night\dmreq{0004}\lsrreq{0104}\reqparam{L1PublicT}

\item There is a new (not yet baselined?) requirement for the calibration pipeline to reduce calibration observations within 1200 seconds

\item A nightly report on data quality, data management system performance and a calibration report have to be generated with 4 hours of the end of the night\dmreq{0096}\reqparam{dq\-Report\-Compl\-Time}

\end{itemize}

Note that there are no computational requirements on individual technical components e.g.. data processing cluster availability, database data retrieval speeds, etc. There is an upper limit on acceptable data loss, and there is a network availability requirement.

\subsubsection{KPMs}


As a proxy for validating the DM system, \citeds{LDM-240} (aka “the spreadsheet”) defined a set of Key Performance Metrics that the system could be verified against. KPMs were not formally flowed down from \citeds{LSE-29} (\LSR) through \citeds{LSE-30} (\OSS) although there is some overlap with \citeds{LSE-29} requirements. [TJ is working on this]. In particular, the non-science KPMs only exist in \citeds{LDM-240} \textit{(spreadsheet/old plan)}.

\begin{note}
While verification was part of the SQuaRE WBS we prepared a KPM verification plan at the request of System Engineering - \citeds{LDM-502}. Need to understand how this fits in DM verification.
\end{note}

\subsection{Interfaces}

We need to verify at the least  interfaces to other subsystems. The ICDs describing external interfaces are curated in Docushare Collection 5201.

%\begin{note}
 % Integration used to be a Tucson role; I believe this is being led by the currently vacant Integration Scientist role? or whoever conducts the operation rehearsals?
%\end{note}

\begin{note}
  Internal interfaces: currently we have no definitions and hence they are not readily verifiable. We have components now though so perhaps we can begin to tackle this as part of each test spec. 
\end{note}
