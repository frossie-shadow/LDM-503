\section{DM Verification Approach \label{approach}}

We intend to verify DM requirements by testing of DM components in a fairly standard engineering manner.
For each high level component a test specification will be produced defining a set of tests related to the requirements for the component. 
These specifications are represented on the top of \figref{fig:doctree}.
Any given  requirement may have several tests associated with it in the specification, the tests may be phased with the need for certain functionality at a specific time. 

The test spec will cover all aspects of the test as outlined in \secref{sect:tsform}. These high level test specifications may call out individual lower level test specification. 

As we execute tests we will gather test reports on the Pass/Fail of the individual tests related to specific requirements.
This Information will allow us to build a Verification Control Document (VCD) (right of \figref{fig:doctree}).
The VCD will provide a \% verification of each requirement in DM (rolled up to OSS requirements also).
\figref {fig:doctree} currently calls for a report from each test spec - this may be captured directly in Jira.




\begin{figure}
\begin{center}
 \includegraphics[width=0.9\textwidth]{images/DocTree}
 \caption{Documentation tree for DM software relating the high level documents to each other. (from \citeds{LDM-294}\label{fig:doctree}}

 \end{center}
 \end{figure}



 The DM components are  outlined in \citeds{LDM-294} and detailed in \citeds{LDM-148}. At a high level these components are represented in figure \figref{fig:dmsdeploy}.  Based on those components we can see the set of Test Specifications needed in \tabref{tab:testspecs}. That table does not contain all of the document numbers yet. 


\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.8\textwidth]{images/DMSDeployment}
		\caption{DM components as deployed during Operations. Where components are
			deployed in multiple locations, the connections between them are labeled with
			the relevant communication protocols. Science payloads are shown in blue.
		\label{fig:dmsdeploy} (from \citeds{LDM-148})}
	\end{center}
\end{figure}

\subsection{Test Items}

\begin{table}
	\caption{Components from LDM-148 with the test specifications to verify them. \label{tab:testspecs}}
	\input{TopLevelTestSpecs}
\end{table}

The test items covered in this test plan are:

\begin{itemize_single}
\item \product \ and its primary components for testing and integration purposes. These are listed in Table \ref{tab:testspecs}. All components listed in orange and yellow have specifications in the corresponding documents listed. Major sub-components in white may have individual test specifications or be addressed in the component they are under depending on applicable factors such as whether they are scheduled for testing at the same time and/or whether they share architectural components or are largely distinct. 

\item The external interfaces between \product and other sub-systems. These are described in [Docushare collection]

\item Operational procedures like Data Release Process and Software Release Process. [We don't have a list]

\end{itemize_single}


  
\subsection{Testing Specification document format}\label{sect:tsform}

The Testing Specification documents are drawn in conjunction with the LSST System Engineer. In all cases they include:

\begin{itemize_single}

\item A list of components being tested within the scope of the Test Specification Document. 

\item A list of features in those components that are being explicitly tested.

\item How those features related to identified requirements for that component
  
\item A description of the environment in which the tests are carried out (eg. hardware platform) and a description of how they differ from the operational system in tests prior to final integration (eg. interfaces that may be mocked without affecting that component's testing). 
  
\item The inputs (eg. data, API load) that are to be used in the test

\item Pass-fail criteria (eg. metrics to be met) 

\item How any outputs that are used to determine pass/fail (eg. data or metrics) are published (made available). 

\item A Software Quality Assurance manifest listing (as relevant) code repositories, configuration information, release/distribution methods and applicable documentation (such as installation instructions, developer guide, user guide etc.)
  
\end{itemize_single}


