


\section{Introduction \label{sect:intro}}

{\bf THERE IS ONLY ONE OF THESE YOU PROBABLY WANT AN STS}


\subsection{Objectives \label{sect:objectives}}

The Software Test Plan describes the system being tested, summarising the system context and decomposition. It sets out the test and verification approach for the system and describes constraints and limitations in the testing to be performed. The STP describes the unit and integration tests for the component modules of the system and describes the validation tests to be performed on the fully integrated system. 

\subsection{Scope \label{sect:scope}}

The Software Test Plan is to be executed by the CU prior to delivery to the DPC where the system will be operated. The DPC will execute integration and acceptance test involving this system within the context of the DPC processing systems.
This document will be updated during the different Gaia cycle phases, according to the requirements updates.

\subsection{Assumptions}  
This paragraph is optional. It describes the preliminary assumptions on which the overall testing strategy are based.
 
\subsection{Applicable Documents \label{sect:ad}}
When applicable documents change a change may be required in this document.
\begin{tabbing}
AUTH-NUM\= \kill 
\citell{LL:TL-001}\>	DPAC Product Assurance Plan \\
\citell{LL:AUTH-XXX} \>	Software Development Plan for \CU \\
\citell{LL:AUTH-XXX}\>	Software Requirements Specification for \product,\\
% perhaps \citell{LL:AUTH-code}\>	Software Requirements Specification for \CU,\\
\end{tabbing}

\subsection{Reference Documents}

\renewcommand{\refname}{}
\bibliographystyle{gaia_aa}
\bibliography{gaia_livelink_valid,gaia_drafts,gaia_refs,gaia_books,gaia_refs_ads}

\subsection{Definitions, acronyms, and abbreviations \label{sect:acronyms}} 
% include acronyms.tex generated by the acronyms.csh (GaiaTools)
\input{acronyms}

\section{Test Items}

The test items covered in this test plan are \product \ and its consituent components:

\begin{itemize_single}
\item All the produsct - from KT diagrams

\item Interfaces  
\item Procedures like Data release 
\end{itemize_single}


\section{Roles and Reporting}

Tester report issues through Jira, but what other mechanisms will be used?

WHo directs OPS rehersals .. ?

Reports on rehersals .. issues and 


Handeling failures - time ines for fix. 


\subsection{Pass/Fail Criteria}

The Software Review Board will meet once a full run of all Test Cases has been performed, and subsequently after a complete run of all outstanding Test Cases.

A Test Case will be considered ``Passed'' when:
\begin{itemize_single}
\item All of the test steps of the Test Case are completed and
\item All open SPRs from this Test Case agreed in Software Review Board are considered noncritical.
\end{itemize_single}

A Test Case will be considered ``Partially Passed'' when:
\begin{itemize_single}
\item Only a subset of all of the test steps in the Test Case are completed but the overall purpose of the test has been met and
\item Any critical SPRs from this Test Case agreed in Software Review Board are still not closed.
\end{itemize_single}

A Test Case will be considered ``Failed'' when:
\begin{itemize_single}
\item Only a subset of all of the test steps in the Test Case are completed and the overall purpose of the test has not been met and
\item Any critical SPRs from this Test Case agreed in Software Review Board are still not closed.
\end{itemize_single}

\section{Constraints and Limitations}

Describes the limitations and the constraints which apply to CU level tests of the system. lack of computing resources may mean that datasets are smaller or that full accuracy cannot be achieved. Explain what must be validated in the DPC tests

\section{Master Schedule}

The schedule for testing the system until launch. If some modules are scheduled for development after other, explain dependencies and impact on integration and validation tests.


Nightly Tests \\

Weekly Integration test with data .. \\

Interface tests ( 2by 2 and integrated E2E, Internal and External)) \\

End to End Tests ?? Freeze software for Ops .. \\

WISE data to PDAC - ...\\

HSC reprocessing - yes see the data and also validate the ops platform . Validate some procedures like install some procedures etc .. \\

ZTF Alerts processing to valiate ALerts pipe .. \\

2018 Specrograph Data Acquasiitong Test..

2018 - Ops rehsal for comissioning - with a weeks comissioning say - pick which parts of plan we could reherase.\\

2019 - Ops rehsal \#2 for comissioning - more complete .\\

2020 - Ops Rehersal Data Release (Comisisoning Data)\\
2021 - Ops Rehersal Data Release (Regular Data)\\


\section{Validation Tools}
\subsection{Introduction}

To evaluate the correctness of the generated data and the systems performances a set of tools may be developed or used. These
tools will provide the means to facilitate the validation tasks. 
Following subsections describe the various tools that can used in the \product validation (e.g. data comparison tools, analysis tools, etc).

\subsection{Data Comparison Tools}
This type of test tools are used to manage products in terms of:
\begin{itemize_single}
\item Comparison of a product generated during a test execution w.r.t. the relevant reference product
\item Non regression verification comparing output products generated by different versions of the same system
\item Measurement of quality degradation due to perturbed inputs
\end{itemize_single}
It allows:
\begin{itemize_single}
\item Product analysis
\item Decoding of generated product allowing to read the most significant data of the product itself
\item Visualisation of the values of a single selected field
\item Apply an accuracy to the comparison
\item Comparing specific parts of the products
\item Filtering using flags values
\end{itemize_single}

\subsection{Data Transformation Tools}
These tools allow the data to be transformed to other formatted data.

\subsection{Analysis Tools}
Descriptions of the performance monitoring tools, profilers, test coverage programs... used in the Performance evaluation tests.\\
...

\section{Unit and Integration Tests}

\subsection{Approach}

Unit and Integration Tests will be automatically executed through the JUnit test framework. The descriptions of the test below are extracted from the test cases code and documentation.The results of Unit and Integration Test to be included in the Sofwtare Test Report will be generated automatically from the output of the execution of the tests by JUnit. A script will be provided to perform thes processing steps.

Module identification? (module tag in class header? mapping file?)

\subsection{Test Coverage}

Test coverage goal for unit and integration testing. Each class and public method shall have a JUnit test harness that may be labelled according to their purpose (e.g. I/O, individual class/method tests, software integration, data model integration etc.). Nominal and contingency
tests should be clearly identified.

Interface coverage...

The tool [insert name of unit test coverage tool here] will be used to provide metrics on the code coverage by Unit Tests for \product \ and this metric will be provide in the Test Report.

\subsection{Unit and Integration Test Specification}

This is a example test plan record; this should be generated automatically.

\begin{longtable} {|p{0.2\textwidth}|p{0.2\textwidth}|p{0.6\textwidth}|}\hline
{\bf Class} & {\bf Unit Test Name} & {\bf Purpose}  \\\hline
Unit Test Class & 
Unit Test Method & 
Purpose of Unit Test from method header \\\hline
\end{longtable}

\input{validation}


\input{scivalidation}
